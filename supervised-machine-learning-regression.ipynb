{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.**","metadata":{}},{"cell_type":"markdown","source":"train regression models on dataset and choosing the best model based on accuracy","metadata":{}},{"cell_type":"markdown","source":"**Brief description of the data set you chose and a summary of its attributes**","metadata":{}},{"cell_type":"markdown","source":"The data contains medical information and costs billed by health insurance companies. It contains 1338 rows of data and the following columns: age, gender, BMI, children, smoker, region, insurance charges.\n\n| S No. | Column | Description| Data Type | Category|\n| --- | --- | --- | --- | --- |\n|1 | Age | age of primary beneficiary | Int | Discrete |\n|2 | Sex | insurance contractor gender, female, male | String | Nominal |\n|3 | BMI | Body mass index, providing an understanding of body, weights that are relatively high or low relative to height | Float | Continuous |\n|4 |Children | Number of children covered by health insurance / Number of dependents | Int | Discrete |\n|5 | Smoker | Smoking status of contractor, yes, no | String | Nominal |\n|6 | Region | the beneficiary's residential area in the US, northeast, southeast, southwest, northwest. | String | Nominal |\n|7 | Charges | Individual medical costs billed by health insurance| Float | Continuous |","metadata":{"id":"FMfEDPyuRLgn"}},{"cell_type":"markdown","source":"**Plan for Data Exploration, Feature Engineering and Modelling**","metadata":{"id":"SaZEfeGtpSyf"}},{"cell_type":"markdown","source":"The steps in solving the Regression Problem are as follows:\n1. Packages to be installed\n2. Load the libraries\n3. Load the dataset\n4. General information about the dataset\n5. Exploratory Data Analysis (EDA)\n6. Modeling\n7. Recommendations","metadata":{}},{"cell_type":"markdown","source":"## Packages to be installed","metadata":{}},{"cell_type":"markdown","source":"1. tpot\n2. auto-sklearn\n3. scipy","metadata":{}},{"cell_type":"code","source":"!conda install -c anaconda swig dask[distributed] --yes\n!pip install deap update_checker tqdm stopit xgboost\n!pip install tpot\n!pip install auto-sklearn\n!pip install 'ray[default]'\n!pip install scikit-optimize\n!pip install scipy==1.7.0","metadata":{"tags":["\"hide-input\"","\"hide-output\""],"execution":{"iopub.status.busy":"2021-08-15T18:28:56.122866Z","iopub.execute_input":"2021-08-15T18:28:56.123418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the libraries","metadata":{}},{"cell_type":"markdown","source":"1. numpy\n2. pandas\n3. matplotlib\n4. seaborn\n5. sklearn\n6. autosklearn\n7. tpot","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, PolynomialFeatures\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.model_selection import ShuffleSplit, RepeatedKFold, cross_val_score, GridSearchCV, cross_val_predict\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, ElasticNet, SGDRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import explained_variance_score\nimport warnings\nfrom scipy.linalg import LinAlgWarning\nfrom sklearn.exceptions import ConvergenceWarning\nimport autosklearn.regression\nfrom tpot import TPOTRegressor","metadata":{"id":"KbNb65InGpDq","tags":["\"hide-input\""],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"markdown","source":"location of dataset","metadata":{}},{"cell_type":"code","source":"dataset = 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'","metadata":{"id":"NWO91BW4F9kT","tags":["\"hide-input\""],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"reading the dataset into dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(dataset)","metadata":{"id":"xIJY1b0-G8i5","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## General information about the dataset","metadata":{"id":"o8nSz0W3V-7Z"}},{"cell_type":"markdown","source":"sampling the data","metadata":{}},{"cell_type":"code","source":"print(df.head())","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1626612527728,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"pevp6tJiHHyG","outputId":"c3e84ba3-acfb-4141-e043-7fe6eb8e6375","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"number of rows and coulmns in dataset","metadata":{}},{"cell_type":"code","source":"print(df.shape)","metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1626612534120,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"8XkwYiBaWWAo","outputId":"7f8b52cb-3832-4172-b0d3-849bc8a6bd3a","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dataset information","metadata":{}},{"cell_type":"code","source":"print(df.info())","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1626612535102,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"gOrvkA4eRIfn","outputId":"597f72d8-6c3f-41a3-ebd0-77c9d04b2b59","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Actions taken for data cleaning and feature engineering**","metadata":{"id":"zznzGhFDpiwP"}},{"cell_type":"markdown","source":"Capitalize column names","metadata":{"id":"i4XNDMeXYX10"}},{"cell_type":"code","source":"df.columns = df.columns.str.capitalize()","metadata":{"id":"wYhwXgG5hMDe","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classifying columns as Numerical or Categorical","metadata":{"id":"wJ5cpRd8dkBX"}},{"cell_type":"code","source":"num_cols = df.select_dtypes('number').columns.tolist()\ncat_cols = df.select_dtypes('object').columns.tolist()","metadata":{"id":"GuTl1qs9adR2","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Features Encoding","metadata":{"id":"GTY4RkbztfGW"}},{"cell_type":"code","source":"oe = OrdinalEncoder()\nsc = StandardScaler()\ndf2 = df.iloc[:,:-1]\nnum_features = num_cols[:-1]\ndf2[cat_cols] = oe.fit_transform(df2[cat_cols])\ndf2[num_features] = sc.fit_transform(df2[num_features])","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Split the data into test and train","metadata":{}},{"cell_type":"code","source":"features = df2.columns\ntarget = df.columns[-1]\nX = df2\nY = df[target]\nss = ShuffleSplit(n_splits=1, test_size=.2, random_state=0)\ntrain_indecies = list(ss.split(X,y=Y))\ntrain_index, test_index = train_indecies[0][0], train_indecies[0][1]\nX_train, X_test = X.loc[train_index], X.loc[test_index]\ny_train, y_test = Y.loc[train_index], Y.loc[test_index]","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"Summary Statistics for Numerical columns","metadata":{}},{"cell_type":"code","source":"print(df.describe())","metadata":{"executionInfo":{"elapsed":534,"status":"ok","timestamp":1626612557592,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"xcmiM2KXbO_K","outputId":"25fa76ae-7119-4a10-b3a9-3b1bfcdf098a","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Summary Statistics for Categorical columns","metadata":{}},{"cell_type":"code","source":"print(df[cat_cols].describe().T)","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1626612559095,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"Lg3K75JJareP","outputId":"013b225f-d989-479f-b457-7ebf723c3a81","tags":["\"hide-input\""],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visual Exploration of Numerical Columns","metadata":{"id":"BEjxYfk_eP3j"}},{"cell_type":"markdown","source":"distribution of Age for candidates","metadata":{}},{"cell_type":"code","source":"df['Age'].hist(bins=5);","metadata":{"executionInfo":{"elapsed":1421,"status":"ok","timestamp":1626612565489,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"rrcKep3GedeF","outputId":"2924e669-008f-4f03-ed17-eb4ffaf114ad","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"correlation between Age and Charges","metadata":{}},{"cell_type":"code","source":"x = df['Age']\ny = df['Charges']\nplt.scatter(x,y)\nplt.xlabel('Age')\nplt.ylabel('Charges');","metadata":{"executionInfo":{"elapsed":62,"status":"ok","timestamp":1626612566550,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"I6PBNC3HrMEr","outputId":"992c5730-588b-4b5b-9439-80caf70167d4","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visual Exploration of Categorical columns","metadata":{"id":"FOrhI8wggunp"}},{"cell_type":"markdown","source":"number of candidates in each region","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df, x='Region',order=df['Region'].value_counts().index);","metadata":{"executionInfo":{"elapsed":973,"status":"ok","timestamp":1626612571784,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"RyNrSPiTkfJ9","outputId":"bb1ef993-7050-4173-a792-9c04b1b3159a","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"distribution of charges for each region","metadata":{}},{"cell_type":"code","source":"sns.boxplot(y=df['Region'], x=df['Charges'],order=df['Region'].value_counts().index);","metadata":{"executionInfo":{"elapsed":584,"status":"ok","timestamp":1626613821794,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"9aHAe9d6sXiJ","outputId":"6a2c6553-4dcb-4f22-bcc1-fc8fe1601af2","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pair plot of numerical features","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[num_cols], plot_kws=dict(alpha=.1, edgecolor='none'));","metadata":{"executionInfo":{"elapsed":2456,"status":"ok","timestamp":1626612730431,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"q_om6VrqzW5H","outputId":"ae0bb3b3-234a-4f3b-efcc-e0454c4a4b60","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"heatmap of numerical features","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df[num_cols]);","metadata":{"executionInfo":{"elapsed":701,"status":"ok","timestamp":1626612772550,"user":{"displayName":"adel ahmed","photoUrl":"","userId":"10327834719883778444"},"user_tz":-420},"id":"ORHG2n3XBoxt","outputId":"efdcc383-cc89-4107-c046-50c31bd38ae6","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"correlation plot of numerical features","metadata":{}},{"cell_type":"code","source":"corr = df.corr()\nmask = np.triu(corr)\nsns.heatmap(corr, mask=mask, cmap='Wistia', center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},  annot= True);","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Importance","metadata":{}},{"cell_type":"code","source":"fe = ExtraTreesRegressor(n_estimators=10)\nfe.fit(X, Y)\nfedf = pd.DataFrame({'Feature':features,'Feature_importance %' : fe.feature_importances_ * 100})\nfedf = fedf.sort_values(by=['Feature_importance %'], ascending=False)\nprint(fedf)\nfedf.plot.bar(x='Feature',y='Feature_importance %');","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"**Summary of training at least three linear regression models which should be variations that cover using a simple linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.**","metadata":{"id":"yV8VVAyqrexV"}},{"cell_type":"markdown","source":"regression models used for the training dataset and the results\n1. LinearRegression\n2. Polynomial\n3. Regularization(ElasticNet)\n4. SGD\n5. Decision Tree \n6. Random Forest\n7. KNN","metadata":{}},{"cell_type":"code","source":"#training the models\nwarnings.filterwarnings('ignore', category=LinAlgWarning)\nwarnings.filterwarnings('ignore', category=ConvergenceWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('Polynomial', LinearRegression()))\nmodels.append(('Regularization', ElasticNet()))\nmodels.append(('SGD', SGDRegressor()))\nmodels.append(('DT', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('KNN', KNeighborsRegressor()))\nresults = []\nnames = []\nfor name, model in models:\n    if name == 'Polynomial':\n        evss = []\n        degrees = np.arange(1, 10)\n        max_evs, min_deg = 1 , 0\n        for deg in degrees:\n            poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n            x_poly_train = poly_features.fit_transform(X_train)\n            poly_reg = model\n            poly_reg.fit(x_poly_train, y_train)\n            x_poly_test = poly_features.fit_transform(X_test)\n            poly_predict = poly_reg.predict(x_poly_test)\n            poly_evs = explained_variance_score(y_test, poly_predict)\n            evss.append(poly_evs)\n            if max_evs > poly_evs:\n                max_evs = poly_evs\n                min_deg = deg\n                \n        poly_features = PolynomialFeatures(degree=min_deg, include_bias=False)\n        x_poly_train = poly_features.fit_transform(X_train)\n        pipeline_p = Pipeline(steps=[('regressor',model)])\n        rkfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n        cv_results_p = cross_val_score(pipeline, x_poly_train, y_train, cv=rkfold , scoring='explained_variance')\n        results.append(cv_results.mean())\n        names.append(name)\n    elif name == 'Regularization':\n        params = {'normalize':[True, False], 'selection':['cyclic', 'random'],\n                  'l1_ratio':np.arange(0, 1, 0.01), 'alpha':np.logspace(-4, 0, 100)}\n        rkfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n        search_r = GridSearchCV(model, params, scoring='explained_variance', cv=rkfold, n_jobs=-1)\n        search_r.fit(X_train, y_train)\n        results.append(search_r.best_score_)\n        names.append(name)\n    elif name == 'KNN':\n        weights = ['uniform', 'distance']\n        algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n        leaf_size = list(range(1,50))\n        n_neighbors = list(range(1,30))\n        p=[1,2]\n        hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p, algorithm=algorithm, weights=weights)\n        rkfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n        search_k = GridSearchCV(model, hyperparameters, scoring='explained_variance', cv=rkfold, n_jobs=-1)\n        search_k.fit(X_train, y_train)\n        results.append(search_k.best_score_)\n        names.append(name)\n        #dfgrid = pd.DataFrame(search_k.cv_results_)\n    else:\n        pipeline = Pipeline(steps=[('regressor',model)])\n        rkfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n        cv_results = cross_val_score(pipeline, X_train, y_train, cv=rkfold , scoring='explained_variance')\n        results.append(cv_results.mean())\n        names.append(name)","metadata":{"tags":["hide-input"],"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare Algorithms\nresults_df = pd.DataFrame({'Regressor': names, 'Explained_Variance': results})\nresults_df = results_df.sort_values(by=['Explained_Variance'], ascending=False)\nprint(results_df)\nresults_df.plot.bar(x='Regressor',y='Explained_Variance');\nplt.title('Algorithm Comparison');","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.**","metadata":{}},{"cell_type":"markdown","source":"Random Forest Regressor have the best score of all regression models for the training sets\n\nso it will be chosen to make the prediction on the test set","metadata":{}},{"cell_type":"code","source":"rkfold_rf = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1)\ntuned_parameters = {'max_depth': [x for x in range(1, 8)] + [None],\n    'max_features': [x for x in range(1, X_train.shape[1])],\n    'min_samples_split': np.linspace(0.1, 1.0, 10),\n    'n_estimators': [x for x in range(1, 100)]}\nsearch_rf = GridSearchCV(RandomForestRegressor(), tuned_parameters, scoring='explained_variance', cv=rkfold_rf, n_jobs=-1)\nsearch_rf.fit(X_train, y_train)\ntesting_predictions = search_rf.predict(X_test)\ntest_accuracy = explained_variance_score(y_test,testing_predictions)\nprint(\"Test-predictions accuracy: \",test_accuracy)","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.**","metadata":{}},{"cell_type":"markdown","source":"* being Smoker is main factor in deciding the insurance charges for the candidate\n* the Random Forest Regressor gave the best results even without GridSearch for the training set, so the model had to be optimized further for the prediction to give the best results possible\n* Polynomial, Regularization, KNN have been tweaked to provide best results on training set (finding best degree, gridsearch of parameters, best k) but stil they produce less accurate results","metadata":{}},{"cell_type":"markdown","source":"## Recommendations","metadata":{}},{"cell_type":"markdown","source":"**Suggestions for next steps in analyzing this data, which may highlight possible flaws in the model and a plan of action to revisit this analysis with additional data or different predictive modeling techniques to achieve a better explanation or a better prediction**","metadata":{"id":"FduJxrVTuBgk"}},{"cell_type":"markdown","source":"using automated machine learning yield better results than manual or gridseached models\n\nfor this dataset will use auto-sklearn and TPOT and compared thier results to results obtained before","metadata":{}},{"cell_type":"code","source":"automl = autosklearn.regression.AutoSklearnRegressor(\n    n_jobs=4,\n    tmp_folder='/tmp/autosklearn_regression_example_tmp',\n)\nautoml.fit(X_train, y_train, dataset_name='insurance')\n#print(automl.leaderboard())\n#print(automl.show_models())\ntrain_predictions = automl.predict(X_train)\nasd = {'Regressor': 'AutoSklearn', 'Explained_Variance': explained_variance_score(y_train, train_predictions)}\n#print(\"Train Explained_Variance_Score:\", as['Explained_Variance'])\n#print(\"Test Explained_Variance_Score:\", sklearn.metrics.explained_variance_score (y_test, test_predictions))","metadata":{"id":"V3oJr2EOuMQ4","tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rkfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\ntpot = TPOTRegressor(n_jobs=-1, generations=10, population_size=10, offspring_size=10, verbosity=0, cv=rkfold, scoring='explained_variance',random_state=1)\ntpot.fit(X_train, y_train)\ntpd = {'Regressor': 'TPOT', 'Explained_Variance': tpot.score(X_test, y_test)}\n#print('Best Pipeline Score= ',tp['Explained_Variance'])","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = results_df.append(asd, ignore_index=True)\nresults_df = results_df.append(tpd, ignore_index=True)\nresults_df = results_df.sort_values(by=['Explained_Variance'], ascending=False)\nprint(results_df)\nresults_df.plot.bar(x='Regressor',y='Explained_Variance');\nplt.title('Algorithm Comparison');","metadata":{"tags":["\"hide-input\""],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the default configuration for automated machine learning give better results than the model that manually selected and modified","metadata":{}}]}